{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVC Data Summaries (with simple method hydrology)\n",
    "\n",
    "## Setup the basic working environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import seaborn\n",
    "seaborn.set(style='ticks', context='paper')\n",
    "\n",
    "import wqio\n",
    "import pybmpdb\n",
    "import pynsqd\n",
    "\n",
    "import pycvc\n",
    "\n",
    "min_precip = 1.9999\n",
    "palette = seaborn.color_palette('deep', n_colors=6)\n",
    "pybmpdb.setMPLStyle()\n",
    "POCs = [p['cvcname'] for p in filter(lambda p: p['include'], pycvc.info.POC_dicts)]\n",
    "\n",
    "if wqio.testing.checkdep_tex() is None:\n",
    "    tex_msg = (\"LaTeX not found on system path. You will \"\n",
    "               \"not be able to compile ISRs to PDF files\")\n",
    "    warnings.warn(tex_msg, UserWarning)\n",
    "    \n",
    "warning_filter = \"ignore\" \n",
    "warnings.simplefilter(warning_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load External Data (this takes a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bmpdb = pycvc.external.bmpdb(palette[3], 'D')\n",
    "nsqdata = pycvc.external.nsqd(palette[2], 'd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CVC Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvcdbfile = \"C:/users/phobson/Desktop/cvc.accdb\"\n",
    "cvcdb = pycvc.Database(cvcdbfile, nsqdata, bmpdb, testing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the site object for the reference site and compute its median values (\"influent\" to other sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LV1 = pycvc.Site(db=cvcdb, siteid='LV-1', raingauge='LV-1', tocentry='Lakeview Control', \n",
    "                 isreference=True,  minprecip=min_precip, color=palette[1], marker='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the reference sites runoff function and assign it to the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LV1_runoff(row):\n",
    "    return LV1.drainagearea.simple_method(row['total_precip_depth'], volume_conversion=0.001)\n",
    "\n",
    "LV1.runoff_fxn = LV1_runoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define \"influent\" medians for each non-reference site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rename_influent_cols(col):\n",
    "    if col.lower() in ['parameter', 'units', 'season']:\n",
    "        newcol = col.lower()\n",
    "    else:\n",
    "        newcol = 'influent {}'.format(col.lower())\n",
    "        \n",
    "    return newcol.replace(' nsqd ', ' ').replace(' effluent ', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lakeview BMP sites get their \"influent\" data from LV-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LV_Influent = (\n",
    "    LV1.medians(\"concentration\", timegroup='season')\n",
    "       .rename(columns={'effluent stat': 'median'})\n",
    "       .rename(columns=rename_influent_cols)\n",
    ")\n",
    "\n",
    "LV1.influentmedians = LV_Influent\n",
    "LV_Influent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elm Drive's \"influent\" data come from NSQD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ED_Influent = (\n",
    "    cvcdb.nsqdata\n",
    "         .seasonal_medians\n",
    "         .rename(columns=rename_influent_cols)\n",
    ")\n",
    "ED_Influent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining site objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ED1 = pycvc.Site(db=cvcdb, siteid='ED-1', raingauge='ED-1',\n",
    "                 tocentry='Elm Drive', influentmedians=ED_Influent, \n",
    "                 minprecip=min_precip, isreference=False,\n",
    "                 color=palette[0], marker='o')\n",
    "\n",
    "LV2 = pycvc.Site(db=cvcdb, siteid='LV-2', raingauge='LV-1',\n",
    "                 tocentry='Lakeview Grass Swale', influentmedians=LV_Influent, \n",
    "                 minprecip=min_precip, isreference=False,\n",
    "                 color=palette[4], marker='^')\n",
    "\n",
    "LV4 = pycvc.Site(db=cvcdb, siteid='LV-4', raingauge='LV-1',\n",
    "                 tocentry=r'Lakeview Bioswale 1$^{\\mathrm{st}}$ South Side', \n",
    "                 influentmedians=LV_Influent, \n",
    "                 minprecip=min_precip, isreference=False,\n",
    "                 color=palette[5], marker='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define runoff, inflow equations and assign to object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elm Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ED1_runoff(row):\n",
    "    return ED1.drainagearea.simple_method(row['total_precip_depth'], volume_conversion=0.001)\n",
    "\n",
    "def ED1_inflow(row):\n",
    "    return ED1_runoff(row)\n",
    "\n",
    "ED1.runoff_fxn = ED1_runoff\n",
    "ED1.inflow_fxn = ED1_inflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lakeview 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LV2_runoff(row):\n",
    "    return LV2.drainagearea.simple_method(row['total_precip_depth'], volume_conversion=0.001)\n",
    "\n",
    "def LV2_inflow(row):\n",
    "    return LV2_runoff(row)\n",
    "\n",
    "LV2.runoff_fxn = LV2_runoff\n",
    "LV2.inflow_fxn = LV2_inflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lakeview 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LV4_runoff(row):\n",
    "    return LV4.drainagearea.simple_method(row['total_precip_depth'], volume_conversion=0.001)\n",
    "\n",
    "def LV4_inflow(row):\n",
    "    return LV4_runoff(row)\n",
    "\n",
    "LV4.runoff_fxn = LV4_runoff\n",
    "LV4.inflow_fxn = LV4_inflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix ED-1 storm that had two composite samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ED1.hydrodata.data.loc['2012-08-10 23:50:00':'2012-08-11 05:20', 'storm'] = 0\n",
    "ED1.hydrodata.data.loc['2012-08-11 05:30':, 'storm'] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use spreadsheet-modeled outflow for the July 8, 2013 event at ED-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# volume from the spreadsheet model\n",
    "modeled_inflow_Liters = 430603\n",
    "modeled_outflow_Liters = 250965\n",
    "\n",
    "# select the big storm\n",
    "storm_date = datetime.date(2013, 7, 8)\n",
    "bigstorm = ED1.storm_info.loc[ED1.storm_info.start_date.dt.date == storm_date].iloc[0]\n",
    "\n",
    "# overwrite values in the storm_info dataframe\n",
    "ED1.storm_info.loc[bigstorm.name, 'inflow_m3'] = modeled_inflow_Liters / pycvc.info.LITERS_PER_CUBICMETER\n",
    "ED1.storm_info.loc[bigstorm.name, 'outflow_m3'] = modeled_outflow_Liters / pycvc.info.LITERS_PER_CUBICMETER\n",
    "\n",
    "# modify the volumes in the individual storm objects\n",
    "ED1.storms[bigstorm.storm_number].total_inflow_volume = modeled_inflow_Liters / pycvc.info.LITERS_PER_CUBICMETER\n",
    "ED1.storms[bigstorm.storm_number].total_outflow_volume = modeled_outflow_Liters / pycvc.info.LITERS_PER_CUBICMETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hydrologic Summary\n",
    "For LV-1 and LV-2, event durations are winsorized to replace outliers beyond the 97.5 percentile.\n",
    "\n",
    "For more information, see:\n",
    "\n",
    "  1. [scipy.stats.mstats.winsorize](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mstats.winsorize.html)\n",
    "  2. [wqio.utils.winsorize_dataframe](https://github.com/Geosyntec/wqio/blob/6a056bee34f9c3ed8e300c3d6db1130a6f9ce980/wqio/utils/misc.py#L1548)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "winsor_limits = {\n",
    "    'ED-1': None,\n",
    "    'LV-1': (0.000, 0.025),\n",
    "    'LV-2': (0.000, 0.025),\n",
    "    'LV-4': None,\n",
    "}\n",
    "\n",
    "with pandas.ExcelWriter(\"output/xlsx/CVCHydro_StormInfo.xlsx\") as stormfile,\\\n",
    "     pandas.ExcelWriter(\"output/xlsx/CVCHydro_StormStats.xlsx\") as allstats,\\\n",
    "     pandas.ExcelWriter(\"output/xlsx/CVCHydro_StormStats_by_Year.xlsx\") as yearstats,\\\n",
    "     pandas.ExcelWriter(\"output/xlsx/CVCHydro_StormStats_by_Season.xlsx\") as seasonstats,\\\n",
    "     pandas.ExcelWriter(\"output/xlsx/CVCHydro_StormStats_by_GroupSeason.xlsx\") as groupstats:\n",
    "\n",
    "    for site in [ED1, LV1, LV2, LV4]:\n",
    "        stat_options = {'duration_hours': winsor_limits[site.siteid]}\n",
    "        site.storm_info.to_excel(stormfile, sheet_name=site.siteid)\n",
    "        site.storm_stats(timegroup=None, **stat_options).to_excel(allstats, sheet_name=site.siteid)\n",
    "        site.storm_stats(timegroup='year', **stat_options).to_excel(yearstats, sheet_name=site.siteid)\n",
    "        site.storm_stats(timegroup='season', **stat_options).to_excel(seasonstats, sheet_name=site.siteid)\n",
    "        site.storm_stats(timegroup='grouped_season', **stat_options).to_excel(groupstats, sheet_name=site.siteid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hydrologic Pairplots \n",
    "Expected failures due to lack of data:\n",
    "  1. LV-2, outflow\n",
    "  1. LV-4, grouped_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for site in [ED1, LV2, LV4]:\n",
    "    for by in ['year', 'outflow', 'season', 'grouped_season']:\n",
    "        try:               \n",
    "            site.hydro_pairplot(by=by)\n",
    "        except:              \n",
    "            print('failed on {}, {}'.format(site, by))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevalence Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pandas.ExcelWriter('output/xlsx/CVCWQ_DataInventory.xlsx') as prev_tables:\n",
    "    for site in [ED1, LV1, LV2, LV4]:\n",
    "        stype = 'composite'\n",
    "        site.prevalence_table()[stype].to_excel(prev_tables, sheet_name='{}'.format(site.siteid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concentrations Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pandas.ExcelWriter('output/xlsx/CVCWQ_ConcStats.xlsx') as allconc, \\\n",
    "     pandas.ExcelWriter('output/xlsx/CVCWQ_ConcStats_by_Year.xlsx') as yearconc, \\\n",
    "     pandas.ExcelWriter('output/xlsx/CVCWQ_ConcStats_by_Season.xlsx') as seasonconc, \\\n",
    "     pandas.ExcelWriter('output/xlsx/CVCWQ_ConcStats_by_GroupedSeason.xlsx') as groupconc:\n",
    "    for site in [ED1, LV1, LV2, LV4]:\n",
    "        sheetopts = dict(sheet_name=site.siteid, na_rep='--')\n",
    "        summaryopts = dict(rescol='concentration', sampletype='composite')\n",
    "        site.wq_summary(timegroup=None, **summaryopts).to_excel(allconc, **sheetopts)\n",
    "        site.wq_summary(timegroup='year', **summaryopts).to_excel(yearconc, **sheetopts)\n",
    "        site.wq_summary(timegroup='season', **summaryopts).to_excel(seasonconc, **sheetopts)\n",
    "        site.wq_summary(timegroup='grouped_season', **summaryopts).to_excel(groupconc, **sheetopts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Loads Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pandas.ExcelWriter('output/xlsx/CVCWQ_SampledLoads.xlsx') as allloads, \\\n",
    "     pandas.ExcelWriter('output/xlsx/CVCWQ_SampledLoads_by_Season.xlsx') as seasonloads, \\\n",
    "     pandas.ExcelWriter('output/xlsx/CVCWQ_SampledLoads_by_GroupedSeason.xlsx') as grouploads, \\\n",
    "     pandas.ExcelWriter('output/xlsx/CVCWQ_SampledLoads_by_Year.xlsx') as yearloads:\n",
    "    for site in [ED1, LV1, LV2, LV4]:\n",
    "        load_opts = dict(sampletype='composite', NAval=0)\n",
    "        sheetopts = dict(sheet_name=site.siteid, na_rep='--')\n",
    "        site.sampled_loads(**load_opts).to_excel(allloads, **sheetopts)\n",
    "        site.sampled_loads(timegroup='season', **load_opts).to_excel(seasonloads, **sheetopts)\n",
    "        site.sampled_loads(timegroup='grouped_season', **load_opts).to_excel(grouploads, **sheetopts)\n",
    "        site.sampled_loads(timegroup='year', **load_opts).to_excel(yearloads, **sheetopts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pandas.ExcelWriter('output/xlsx/CVCWQ_LoadStats.xlsx') as allloads, \\\n",
    "     pandas.ExcelWriter('output/xlsx/CVCWQ_LoadStats_by_Year.xlsx') as yearloads, \\\n",
    "     pandas.ExcelWriter('output/xlsx/CVCWQ_LoadStats_by_Season.xlsx') as seasonloads, \\\n",
    "     pandas.ExcelWriter('output/xlsx/CVCWQ_LoadStats_by_GroupedSeason.xlsx') as grouploads:\n",
    "    for site in [ED1, LV1, LV2, LV4]:\n",
    "        sheetopts = dict(sheet_name=site.siteid, na_rep='--')\n",
    "        summaryopts = dict(rescol='load_outflow', sampletype='composite')\n",
    "        site.wq_summary(timegroup=None, **summaryopts).to_excel(allloads, **sheetopts)\n",
    "        site.wq_summary(timegroup='year', **summaryopts).to_excel(yearloads, **sheetopts)\n",
    "        site.wq_summary(timegroup='season', **summaryopts).to_excel(seasonloads, **sheetopts)\n",
    "        site.wq_summary(timegroup='grouped_season', **summaryopts).to_excel(grouploads, **sheetopts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pandas.ExcelWriter('output/xlsx/CVCWQ_TidyData.xlsx') as tidyfile:\n",
    "    for site in [ED1, LV1, LV2, LV4]:\n",
    "        site.tidy_data.to_excel(tidyfile, sheet_name=site.siteid, na_rep='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seaborn.set(style='ticks', context='paper')\n",
    "pybmpdb.setMPLStyle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Storm Reports\n",
    "(requires $\\LaTeX$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for site in [ED1, LV1, LV2, LV4]:\n",
    "    print('\\n----Compiling ISR for {0}----'.format(site.siteid))\n",
    "    site.allISRs('composite', version='draft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precip-outflow scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for site in [ED1, LV1, LV2, LV4]:\n",
    "    print('\\n----Summarizing {0}----'.format(site.siteid))\n",
    "    \n",
    "    site.hydro_jointplot(\n",
    "        xcol='total_precip_depth', \n",
    "        ycol='outflow_mm', \n",
    "        conditions=\"outflow_mm > 0\", \n",
    "        one2one=True\n",
    "    )\n",
    "\n",
    "    site.hydro_jointplot(\n",
    "        xcol='antecedent_days', \n",
    "        ycol='outflow_mm', \n",
    "        conditions=\"outflow_mm > 0\", \n",
    "        one2one=False\n",
    "    )\n",
    "\n",
    "    site.hydro_jointplot(\n",
    "        xcol='total_precip_depth', \n",
    "        ycol='antecedent_days', \n",
    "        conditions=\"outflow_mm == 0\", \n",
    "        one2one=False\n",
    "    )\n",
    "    \n",
    "    site.hydro_jointplot(\n",
    "        xcol='peak_precip_intensity', \n",
    "        ycol='peak_outflow', \n",
    "        conditions=None, \n",
    "        one2one=False\n",
    "    )\n",
    "    \n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WQ Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists of sites to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "site_lists = [\n",
    "    [ED1],\n",
    "    [LV1, LV2, LV4],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sl in site_lists:\n",
    "    print('\\n----Comparing {}----'.format(', '.join([s.siteid for s in sl])))\n",
    "    for poc in POCs:\n",
    "        print('  ' + poc)\n",
    "        \n",
    "        wqcomp = pycvc.summary.WQComparison(sl, 'composite', poc, nsqdata, bmpdb)\n",
    "        \n",
    "        wqcomp.seasonalBoxplots(load=False, finalOutput=True)\n",
    "        wqcomp.seasonalBoxplots(load=True, finalOutput=True)\n",
    "        \n",
    "        wqcomp.landuseBoxplots(finalOutput=True)\n",
    "        wqcomp.bmpCategoryBoxplots(finalOutput=True)\n",
    "        \n",
    "        wqcomp.parameterStatPlot(finalOutput=True)\n",
    "        wqcomp.parameterStatPlot(load=True, finalOutput=True)\n",
    "        \n",
    "        wqcomp.parameterTimeSeries(finalOutput=True)  \n",
    "        wqcomp.parameterTimeSeries(load=True, finalOutput=True)  \n",
    "\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Megafigures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sl in site_lists:\n",
    "    print('\\n----Megafigs with {}----'.format(', '.join([s.siteid for s in sl])))\n",
    "    \n",
    "    # construct the megafigures\n",
    "    mf1 = pycvc.summary.WQMegaFigure(sl, 'composite', POCs[:6], 1, nsqdata, bmpdb)\n",
    "    mf2 = pycvc.summary.WQMegaFigure(sl, 'composite', POCs[6:], 2, nsqdata, bmpdb)\n",
    "    for n, mf in enumerate([mf1, mf2]):\n",
    "        print('\\tTime Series {0}'.format(n+1))\n",
    "        mf.timeseriesFigure(load=False)\n",
    "        mf.timeseriesFigure(load=True)\n",
    "\n",
    "        print('\\tStat plots {0}'.format(n+1))\n",
    "        mf.statplotFigure(load=False)\n",
    "        mf.statplotFigure(load=True)\n",
    "\n",
    "        print('\\tBMPDB Boxplots {0}'.format(n+1))\n",
    "        mf.bmpCategoryBoxplotFigure()\n",
    "\n",
    "        print('\\tNSQD Boxplots {0}'.format(n+1))\n",
    "        mf.landuseBoxplotFigure()\n",
    "\n",
    "        print('\\tSeasonal Boxplots {0}'.format(n+1))\n",
    "        mf.seasonalBoxplotFigure(load=False)\n",
    "        mf.seasonalBoxplotFigure(load=True)\n",
    "     \n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsampled loading estimates\n",
    "*Warning*: Site objects (e.g., `ED1`) have hidden `_unsampled_loading_estimates` methods that return load estimates of unsampled storms using the estimated median influent concentrations and median effluent concentrations. However, it is highly recommended that you aggregate the data and don't draw conclusions about individual storms.\n",
    "\n",
    "The cell below aggregates the data for each parameter, season, and whether the storms produced outflow. The results (sums) are then saved to an Excel file, one tab for each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pandas.ExcelWriter(\"output/xlsx/CVCWQ_UnsampledLoadEstimates.xlsx\") as unsampled_all, \\\n",
    "     pandas.ExcelWriter(\"output/xlsx/CVCWQ_UnsampledLoadEstimates_by_Season.xlsx\") as unsampled_seasons, \\\n",
    "     pandas.ExcelWriter(\"output/xlsx/CVCWQ_UnsampledLoadEstimates_by_GroupedSeason.xlsx\") as unsampled_groups, \\\n",
    "     pandas.ExcelWriter(\"output/xlsx/CVCWQ_UnsampledLoadEstimates_by_Year.xlsx\") as unsampled_years:\n",
    "    for site in [ED1, LV1, LV2, LV4]:\n",
    "        site._unsampled_load_estimates(NAval=0).to_excel(unsampled_all, sheet_name=site.siteid)\n",
    "        site._unsampled_load_estimates(NAval=0, timegroup='season').to_excel(unsampled_seasons, sheet_name=site.siteid)\n",
    "        site._unsampled_load_estimates(NAval=0, timegroup='grouped_season').to_excel(unsampled_groups, sheet_name=site.siteid)\n",
    "        site._unsampled_load_estimates(NAval=0, timegroup='year').to_excel(unsampled_years, sheet_name=site.siteid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
